
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>The First Distinction â€“ Cognitive Scaffold v4 (Multi-Agent)</title>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.2/p5.min.js"></script>
  <style>
    body { margin: 0; overflow: hidden; background: black; }
    #ui { position: absolute; bottom: 10px; left: 10px; color: white; font-family: sans-serif; }
  </style>
</head>
<body>
<div id="ui">
  <button onclick="downloadLogs()">Download Logs</button>
</div>
<script>
let gridSize = 20, cellSize = 25;
let grid = [], agents = [], ruleSet = ['A', 'B', 'C'], ruleIndex = 0, currentRule = ruleSet[ruleIndex];
let entropyLog = [], actionLog = [];

function setup() {
  createCanvas(gridSize * cellSize, gridSize * cellSize);
  frameRate(5);
  initGrid();
  agents.push(new Agent("A", {i: 5, j: 5}));
  agents.push(new Agent("B", {i: 15, j: 15}));
}

function initGrid() {
  for (let i = 0; i < gridSize; i++) {
    grid[i] = [];
    for (let j = 0; j < gridSize; j++) {
      grid[i][j] = 0;
    }
  }
  for (let agent of agents) {
    grid[agent.pos.i][agent.pos.j] = 2;
  }
}

function drawGrid() {
  background(0);
  for (let i = 0; i < gridSize; i++) {
    for (let j = 0; j < gridSize; j++) {
      stroke(50);
      if (grid[i][j] === 2) fill('red');
      else fill(grid[i][j] === 1 ? 255 : 0);
      rect(j * cellSize, i * cellSize, cellSize, cellSize);
    }
  }
}

function calculateEntropy(grid) {
  let flat = grid.flat().filter(v => v < 2);
  let active = flat.filter(v => v === 1).length;
  return active / flat.length;
}

function updateGrid(grid, rule) {
  let newGrid = [];
  for (let i = 0; i < gridSize; i++) {
    newGrid[i] = [];
    for (let j = 0; j < gridSize; j++) {
      let total = 0;
      for (let x = -1; x <= 1; x++) {
        for (let y = -1; y <= 1; y++) {
          let ni = i + x, nj = j + y;
          if (ni >= 0 && ni < gridSize && nj >= 0 && nj < gridSize && grid[ni][nj] === 1) total++;
        }
      }
      if (grid[i][j] === 2) {
        newGrid[i][j] = 2;
      } else {
        if (rule === 'A') {
          newGrid[i][j] = (grid[i][j] === 0 && total === 1) ? 1 : (grid[i][j] === 1 && total >= 3) ? 0 : grid[i][j];
        } else if (rule === 'B') {
          newGrid[i][j] = (grid[i][j] === 0 && total === 2) ? 1 : (grid[i][j] === 1 && total <= 1) ? 0 : grid[i][j];
        } else {
          newGrid[i][j] = (grid[i][j] === 0 && total === 3) ? 1 : (grid[i][j] === 1 && (total < 2 || total > 3)) ? 0 : grid[i][j];
        }
      }
    }
  }
  return newGrid;
}

class Agent {
  constructor(id, pos) {
    this.id = id;
    this.pos = pos;
    this.prevEntropy = 0;
    this.memory = [];
    this.stimCounter = 0;
  }

  sense(entropy, sharedMsg) {
    this.reward = entropy - this.prevEntropy;
    this.prevEntropy = entropy;
    this.memory.push({ entropy: entropy, reward: this.reward, msg: sharedMsg });
    if (this.memory.length > 20) this.memory.shift();
  }

  act(rule) {
    let avgReward = this.memory.reduce((sum, e) => sum + e.reward, 0) / this.memory.length;
    if (avgReward < -0.05) return 'stimulate';
    if (this.prevEntropy < 0.1 && this.stimCounter < 2) { this.stimCounter++; return 'stimulate'; }
    return 'move';
  }

  move() {
    let options = [
      {i: this.pos.i - 1, j: this.pos.j},
      {i: this.pos.i + 1, j: this.pos.j},
      {i: this.pos.i, j: this.pos.j - 1},
      {i: this.pos.i, j: this.pos.j + 1}
    ];
    let valid = options.filter(p => p.i >= 0 && p.i < gridSize && p.j >= 0 && p.j < gridSize);
    if (valid.length > 0) {
      grid[this.pos.i][this.pos.j] = 0;
      let next = random(valid);
      this.pos = {i: next.i, j: next.j};
      grid[this.pos.i][this.pos.j] = 2;
    }
  }

  stimulate() {
    for (let dx = -1; dx <= 1; dx++) {
      for (let dy = -1; dy <= 1; dy++) {
        let ni = this.pos.i + dx, nj = this.pos.j + dy;
        if (ni >= 0 && ni < gridSize && nj >= 0 && nj < gridSize && grid[ni][nj] === 0) {
          grid[ni][nj] = 1;
        }
      }
    }
  }
}

function draw() {
  let entropy = calculateEntropy(grid);
  entropyLog.push(entropy);

  // Shared message: average reward from all agents
  let sharedMsg = agents.map(a => a.reward || 0).reduce((a, b) => a + b, 0) / agents.length;

  for (let agent of agents) {
    agent.sense(entropy, sharedMsg);
    let action = agent.act(currentRule);
    if (action === 'move') agent.move();
    if (action === 'stimulate') agent.stimulate();

    actionLog.push({
      frame: frameCount,
      agent: agent.id,
      action: action,
      entropy: entropy,
      rule: currentRule
    });
  }

  grid = updateGrid(grid, currentRule);
  drawGrid();
}

function downloadLogs() {
  const data = { entropyLog: entropyLog, actionLog: actionLog };
  const blob = new Blob([JSON.stringify(data, null, 2)], { type: 'application/json' });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = 'cognitive_scaffold_v4_log.json';
  a.click();
  URL.revokeObjectURL(url);
}
</script>
</body>
</html>
